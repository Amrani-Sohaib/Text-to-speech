import torch
from TTS.api import TTS


# Get device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
# List available ğŸ¸TTS models
print(TTS().list_models())

# Init TTS
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

content = """  ÙŠÙ…Ø«Ù„ Ø¥ÙŠØ±ÙŠÙ† ÙŠÙŠØºØ± Ø´Ø®ØµÙŠØ© Ù…Ø¹Ù‚Ø¯Ø© ÙÙŠ Ø¹Ù„Ø§Ù‚ØªÙ‡Ø§ Ø¨Ø§Ù„ÙÙ„Ø³ÙØ© Ø§Ù„Ø¹Ø¯Ù…ÙŠØ©. ÙØ¨Ø¹Ø¯ Ø§ÙƒØªØ´Ø§ÙÙ‡ Ù„Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„Ù…Ø±ÙŠØ±Ø© Ø­ÙˆÙ„ Ø¹Ø§Ù„Ù…Ù‡ ÙˆØ§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø£Ø³Ø§ÙˆÙŠ Ù„Ø´Ø¹Ø¨Ù‡ØŒ ÙŠØªØ­ÙˆÙ„ ØªÙÙƒÙŠØ±Ù‡ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ù†Ø­Ùˆ Ø±Ø¤ÙŠØ© Ø¹Ø¯Ù…ÙŠØ© Ù„Ù„ÙˆØ¬ÙˆØ¯. ÙŠØ±Ù‰ Ø£Ù† Ø§Ù„Ù…Ø¹Ø§Ù†Ø§Ø© ÙˆØ§Ù„ØµØ±Ø§Ø¹ Ù‡Ù…Ø§ Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø­ÙŠØ§Ø©ØŒ ÙˆØ£Ù† Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù†Ù‰ Ø£Ùˆ Ù‚ÙŠÙ… Ù…Ø·Ù„Ù‚Ø© Ù‡Ùˆ ÙˆÙ‡Ù…. Ù‡Ø°Ø§ Ø§Ù„ØªØ­ÙˆÙ„ Ø§Ù„ÙÙ„Ø³ÙÙŠ ÙŠØ¯ÙØ¹Ù‡ Ù„Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ù…ØªØ·Ø±ÙØ©ØŒ Ù…Ø¹ØªÙ‚Ø¯Ø§Ù‹ Ø£Ù† Ø§Ù„Ø­Ø±ÙŠØ© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ØªÙƒÙ…Ù† ÙÙŠ Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªØ¯Ù…ÙŠØ± Ø§Ù„Ø¹Ø§Ù„Ù… ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„Ù‡ØŒ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø°Ù„Ùƒ ÙŠØ¹Ù†ÙŠ Ø§Ù„ØªØ®Ù„ÙŠ Ø¹Ù† Ø¥Ù†Ø³Ø§Ù†ÙŠØªÙ‡ ÙˆÙ‚ÙŠÙ…Ù‡ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©."""

# Run TTS
# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
#wav = tts.tts(text=content, speaker_wav="C:\Users\Sohaib\ReopML\Text-to-speech\generated_audios\Ahmed deep test python_1.wav", language="ara")
# Text to speech to a file
tts.tts_to_file(text=content, speaker_wav=r"C:\Users\Sohaib\ReopML\Text-to-speech\audios\full_audios\Ø§Ù„Ø£Ø³Ø¯ ÙˆØ§Ù„Ø®Ø±ÙˆÙ ÙˆÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨ÙŠ.wav", language="ar", file_path="output.wav")